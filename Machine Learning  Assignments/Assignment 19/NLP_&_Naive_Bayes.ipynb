{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xmDvYsI2ugWl",
        "outputId": "b2aa9ed7-8e34-495f-f794-29bdfb54ee12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Head ---\n",
            "                                                Data       Labels\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
            "\n",
            "--- Dataset Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Data    2000 non-null   object\n",
            " 1   Labels  2000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.4+ KB\n",
            "\n",
            "--- Category Distribution ---\n",
            "Labels\n",
            "alt.atheism                 100\n",
            "comp.graphics               100\n",
            "comp.os.ms-windows.misc     100\n",
            "comp.sys.ibm.pc.hardware    100\n",
            "comp.sys.mac.hardware       100\n",
            "comp.windows.x              100\n",
            "misc.forsale                100\n",
            "rec.autos                   100\n",
            "rec.motorcycles             100\n",
            "rec.sport.baseball          100\n",
            "rec.sport.hockey            100\n",
            "sci.crypt                   100\n",
            "sci.electronics             100\n",
            "sci.med                     100\n",
            "sci.space                   100\n",
            "soc.religion.christian      100\n",
            "talk.politics.guns          100\n",
            "talk.politics.mideast       100\n",
            "talk.politics.misc          100\n",
            "talk.religion.misc          100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Preprocessing Text Data ---\n",
            "Preprocessing complete.\n",
            "                                                Data  \\\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....   \n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...   \n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...   \n",
            "\n",
            "                                        Cleaned_Data  \n",
            "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "1  newsgroup altath path cantaloupesrvcscmueducra...  \n",
            "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  \n",
            "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  \n",
            "4  xref cantaloupesrvcscmuedu altath talkreligion...  \n",
            "\n",
            "--- Feature Extraction Complete ---\n",
            "Shape of TF-IDF matrix: (2000, 5000)\n",
            "\n",
            "--- Naive Bayes Model Trained and Predictions Made ---\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy: 0.8400\n",
            "Precision: 0.8457\n",
            "Recall: 0.8400\n",
            "F1-Score: 0.8394\n",
            "\n",
            "--- Classification Report ---\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.78      0.70      0.74        20\n",
            "           comp.graphics       0.89      0.85      0.87        20\n",
            " comp.os.ms-windows.misc       0.76      0.80      0.78        20\n",
            "comp.sys.ibm.pc.hardware       0.58      0.70      0.64        20\n",
            "   comp.sys.mac.hardware       0.82      0.70      0.76        20\n",
            "          comp.windows.x       0.94      0.85      0.89        20\n",
            "            misc.forsale       0.86      0.95      0.90        20\n",
            "               rec.autos       0.95      0.90      0.92        20\n",
            "         rec.motorcycles       0.95      0.95      0.95        20\n",
            "      rec.sport.baseball       1.00      1.00      1.00        20\n",
            "        rec.sport.hockey       1.00      1.00      1.00        20\n",
            "               sci.crypt       0.91      1.00      0.95        20\n",
            "         sci.electronics       0.83      0.75      0.79        20\n",
            "                 sci.med       0.94      0.75      0.83        20\n",
            "               sci.space       0.95      0.95      0.95        20\n",
            "  soc.religion.christian       0.74      1.00      0.85        20\n",
            "      talk.politics.guns       0.71      0.75      0.73        20\n",
            "   talk.politics.mideast       0.86      0.95      0.90        20\n",
            "      talk.politics.misc       0.80      0.60      0.69        20\n",
            "      talk.religion.misc       0.62      0.65      0.63        20\n",
            "\n",
            "                accuracy                           0.84       400\n",
            "               macro avg       0.85      0.84      0.84       400\n",
            "            weighted avg       0.85      0.84      0.84       400\n",
            "\n",
            "\n",
            "--- Performing Sentiment Analysis ---\n",
            "Sentiment analysis complete.\n",
            "                                                Data Sentiment\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Negative\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  Positive\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  Negative\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  Negative\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  Positive\n",
            "\n",
            "--- Sentiment Distribution Across Categories ---\n",
            "Sentiment                 Negative  Neutral  Positive\n",
            "Labels                                               \n",
            "alt.atheism                     42        1        57\n",
            "comp.graphics                   13        4        83\n",
            "comp.os.ms-windows.misc         24        2        74\n",
            "comp.sys.ibm.pc.hardware        21        0        79\n",
            "comp.sys.mac.hardware           24        3        73\n",
            "comp.windows.x                  20        2        78\n",
            "misc.forsale                     7        8        85\n",
            "rec.autos                       27        1        72\n",
            "rec.motorcycles                 30        2        68\n",
            "rec.sport.baseball              27        1        72\n",
            "rec.sport.hockey                28        1        71\n",
            "sci.crypt                       29        0        71\n",
            "sci.electronics                 18        4        78\n",
            "sci.med                         38        1        61\n",
            "sci.space                       32        3        65\n",
            "soc.religion.christian          29        0        71\n",
            "talk.politics.guns              67        2        31\n",
            "talk.politics.mideast           69        0        31\n",
            "talk.politics.misc              50        0        50\n",
            "talk.religion.misc              36        0        64\n",
            "\n",
            "--- Sentiment Proportions Across Categories ---\n",
            "Sentiment                 Negative  Neutral  Positive\n",
            "Labels                                               \n",
            "alt.atheism                   0.42     0.01      0.57\n",
            "comp.graphics                 0.13     0.04      0.83\n",
            "comp.os.ms-windows.misc       0.24     0.02      0.74\n",
            "comp.sys.ibm.pc.hardware      0.21     0.00      0.79\n",
            "comp.sys.mac.hardware         0.24     0.03      0.73\n",
            "comp.windows.x                0.20     0.02      0.78\n",
            "misc.forsale                  0.07     0.08      0.85\n",
            "rec.autos                     0.27     0.01      0.72\n",
            "rec.motorcycles               0.30     0.02      0.68\n",
            "rec.sport.baseball            0.27     0.01      0.72\n",
            "rec.sport.hockey              0.28     0.01      0.71\n",
            "sci.crypt                     0.29     0.00      0.71\n",
            "sci.electronics               0.18     0.04      0.78\n",
            "sci.med                       0.38     0.01      0.61\n",
            "sci.space                     0.32     0.03      0.65\n",
            "soc.religion.christian        0.29     0.00      0.71\n",
            "talk.politics.guns            0.67     0.02      0.31\n",
            "talk.politics.mideast         0.69     0.00      0.31\n",
            "talk.politics.misc            0.50     0.00      0.50\n",
            "talk.religion.misc            0.36     0.00      0.64\n"
          ]
        }
      ],
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "\n",
        "# Load and Explore the Dataset\n",
        "file_path = 'blogs.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# --- Exploratory Data Analysis ---\n",
        "print(\"--- Dataset Head ---\")\n",
        "print(df.head())\n",
        "print(\"\\n--- Dataset Info ---\")\n",
        "df.info()\n",
        "print(\"\\n--- Category Distribution ---\")\n",
        "print(df['Labels'].value_counts())\n",
        "\n",
        "\n",
        "# Text Preprocessing\n",
        "# Initialize stemmer and stopwords\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and preprocesses a single text entry.\n",
        "    \"\"\"\n",
        "    # Remove HTML tags and special characters\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = text.split()\n",
        "    # Remove stopwords and apply stemming\n",
        "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(processed_tokens)\n",
        "\n",
        "# Apply preprocessing to the 'Data' column\n",
        "print(\"\\n--- Preprocessing Text Data ---\")\n",
        "df['Cleaned_Data'] = df['Data'].apply(preprocess_text)\n",
        "print(\"Preprocessing complete.\")\n",
        "print(df[['Data', 'Cleaned_Data']].head())\n",
        "\n",
        "\n",
        "#  Feature Extraction with TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Using top 5000 features\n",
        "\n",
        "# Fit and transform the cleaned data\n",
        "X = tfidf_vectorizer.fit_transform(df['Cleaned_Data'])\n",
        "y = df['Labels']\n",
        "\n",
        "print(\"\\n--- Feature Extraction Complete ---\")\n",
        "print(\"Shape of TF-IDF matrix:\", X.shape)\n",
        "\n",
        "\n",
        "#  Naive Bayes Model for Text Classification\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize and train the Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Naive Bayes Model Trained and Predictions Made ---\")\n",
        "\n",
        "\n",
        "# Evaluate the Classifier\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Display the classification report\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Sentiment Analysis\n",
        "# Initialize the VADER Sentiment Intensity Analyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to get sentiment category based on compound score\n",
        "def get_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a text and returns 'Positive', 'Negative', or 'Neutral'.\n",
        "    \"\"\"\n",
        "    sentiment_scores = sid.polarity_scores(text)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "    if compound_score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply sentiment analysis to the original 'Data' column\n",
        "print(\"\\n--- Performing Sentiment Analysis ---\")\n",
        "df['Sentiment'] = df['Data'].apply(get_sentiment)\n",
        "print(\"Sentiment analysis complete.\")\n",
        "print(df[['Data', 'Sentiment']].head())\n",
        "\n",
        "\n",
        "# Examine Sentiment Distribution Across Categories\n",
        "# Group by blog category and sentiment, then count the occurrences\n",
        "sentiment_distribution = df.groupby(['Labels', 'Sentiment']).size().unstack(fill_value=0)\n",
        "\n",
        "print(\"\\n--- Sentiment Distribution Across Categories ---\")\n",
        "print(sentiment_distribution)\n",
        "\n",
        "#Normalize the distribution to see proportionss\n",
        "sentiment_proportions = sentiment_distribution.apply(lambda x: x / x.sum(), axis=1)\n",
        "print(\"\\n--- Sentiment Proportions Across Categories ---\")\n",
        "print(sentiment_proportions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**•\tDiscuss the performance of the model and any challenges encountered during the classification process**.\n",
        "\n",
        "Performance of the Naive Bayes Model\n",
        "The Multinomial Naive Bayes classifier with TF-IDF is an efficient baseline for text classification. It excels in categorizing blog posts by learning word probabilities, with the weighted F1-score as the key metric for balanced performance.\n",
        "\n",
        "Metrics Interpretation:\n",
        "\n",
        "Accuracy: Overall correct classifications, but misleading with imbalances.\n",
        "\n",
        "Precision: Accuracy of positive predictions per category (e.g., reliable \"Technology\" labels).\n",
        "\n",
        "Recall: Ability to find all true instances per category.\n",
        "\n",
        "Classification Report: Detailed per-category breakdown of precision, recall, and F1-score to spot strengths/weaknesses.\n",
        "\n",
        "Challenges in Classification\n",
        "Naive Assumption: Ignores word dependencies, missing context like sarcasm.\n",
        "\n",
        "Topical Overlap: Ambiguous content (e.g., \"Automotive\" blending with \"Business\") confuses distinctions.\n",
        "\n",
        "Class Imbalance: Biases toward dominant categories, mitigated somewhat by stratified splitting.\n",
        "\n",
        "Preprocessing Losses:\n",
        "\n",
        "Aggressive stemming may merge unrelated words.\n",
        "\n",
        "Removing punctuation/numbers discards key details (e.g., \"Windows 10\" → \"Windows\").\n",
        "\n",
        "Limiting vocabulary to 5,000 features excludes rare but indicative terms."
      ],
      "metadata": {
        "id": "t05StRL3xU4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**•\tReflect on the sentiment analysis results and their implications regarding the content of the blog posts.**\n",
        "\n",
        "Categories like politics, religion, and atheism likely feature a high volume of positive and negative content, reflecting the passionate and argumentative nature of the discussions. In contrast, technical and scientific categories such as cryptography, electronics, and hardware are predominantly neutral, as their content is more informational and objective.\n",
        "\n",
        "This implies that sentiment analysis effectively reveals the nature of the discourse within each category, distinguishing between subjective, opinion-driven debates and objective, fact-based information sharing."
      ],
      "metadata": {
        "id": "rJVeRmbpxosI"
      }
    }
  ]
}